import csv
import io
from traceback import format_exc

from common import stats
from payer_accumulator.accumulation_mapping_service import AccumulationMappingService
from payer_accumulator.accumulation_report_service import AccumulationReportService
from payer_accumulator.common import PayerName
from payer_accumulator.csv.csv_accumulation_file_generator import (
    CSV_DELIMITER,
    CSVAccumulationFileGenerator,
)
from payer_accumulator.file_handler import AccumulationFileHandler
from payer_accumulator.tasks.rq_payer_accumulation_response_processing import (
    METRIC_PREFIX,
    TASK_RUN_METRIC,
    AccumulationResponseProcessingJob,
)
from storage.connection import db
from tasks.queues import job
from utils.log import logger

log = logger(__name__)


class AccumulationCSVResponseProcessingJob(AccumulationResponseProcessingJob):
    """
    Job to process CSV response files from payers.
    Expects CSV files in the format generated by AccumulationCSVFileGeneratorBCBSMA
    and other CSV file generators.
    """

    def __init__(self, payer_name: PayerName):
        self.payer_name = payer_name
        self.file_handler = AccumulationFileHandler()

        # Override file_generator with CSV-specific generator
        file_generator = AccumulationReportService.get_generator_class_for_payer_name(
            payer_name=payer_name.value
        )

        # Verify the file generator supports CSV format
        if not isinstance(file_generator, CSVAccumulationFileGenerator):
            raise RuntimeError(
                f"Incompatible File Generator for {payer_name} - must be a CSV file generator"
            )

        # Override the parent's file_generator with our CSV-specific one
        self.file_generator = file_generator  # type: ignore[assignment]
        self.session = db.session
        self.mapping_service = AccumulationMappingService(session=self.session)

    def process_accumulation_response_file(self, file_name: str) -> int:
        """Process a single CSV response file."""
        log.info(
            "Processing accumulation response",
            payer_name=self.payer_name.value,
            file_name=file_name,
        )

        file_contents = self.download_accumulation_response_file(file_name)

        # Parse CSV contents
        csv_file = io.StringIO(file_contents)
        csv_reader = csv.DictReader(csv_file, delimiter=CSV_DELIMITER)

        # Process each row
        records = list(csv_reader)
        if not records:
            log.warning(f"No records found in response file {file_name}")
            return 0

        process_stats = self.process_accumulation_response_records(records)

        log.info(
            "Successfully processed accumulation response file",
            payer_name=self.payer_name.value,
            file_name=file_name,
            **process_stats,
        )

        return process_stats["total_records"]


def process_csv_accumulation_responses(
    payer_name: PayerName,
) -> None:

    log.info("Starting accumulation response processing", payer_name=payer_name)

    try:
        response_processing_job = AccumulationCSVResponseProcessingJob(
            payer_name=payer_name
        )
        response_processing_job.run()
    except Exception as e:
        log.error(
            "Failed to process accumulation response",
            payer_name=payer_name.value,
            reason=format_exc(),
            error_message=str(e),
        )

    log.info("Finished accumulation response processing", payer_name=payer_name)
    stats.increment(
        metric_name=f"{METRIC_PREFIX}.{TASK_RUN_METRIC}",
        pod_name=stats.PodNames.PAYMENTS_PLATFORM,
    )


@job(service_ns="payer_accumulation", team_ns="payments_platform")
def bcbs_ma_process_accumulation_responses() -> None:
    process_csv_accumulation_responses(payer_name=PayerName.BCBS_MA)
